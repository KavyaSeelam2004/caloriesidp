{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KavyaSeelam2004/caloriesidp/blob/main/CALORIES_PREDICTION_IDP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnWLVDNbje9M"
      },
      "outputs": [],
      "source": [
        "# import required libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "#from sklearn.linear_model import Ridge,Lasso\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn import metrics\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import pickle\n",
        "\n",
        "import warnings\n",
        "from warnings import filterwarnings\n",
        "filterwarnings(\"ignore\")\n",
        "\n",
        "sns.set()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the Calories dataset\n",
        "import pandas as pd\n",
        "\n",
        "df1 = pd.read_csv(\"/content/calories.csv\")\n",
        "df1.head()"
      ],
      "metadata": {
        "id": "f5X67aJFj4B5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.shape"
      ],
      "metadata": {
        "id": "YFcZAmbHj56B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.read_csv(\"/content/exercise.csv\")\n",
        "df2.head()"
      ],
      "metadata": {
        "id": "-Z38lmklj8Su"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.shape"
      ],
      "metadata": {
        "id": "I0RdZhqOj-IR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([df2,df1[\"Calories\"]],axis=1)"
      ],
      "metadata": {
        "id": "CWkKS1aIkAMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "vlfX9gFXkCSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "kzXdborrkEAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "b2WRlSdNkFvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "BSXBgS22kHam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns = [\"User_ID\"],axis=1,inplace =True)"
      ],
      "metadata": {
        "id": "ioWhfzz2kJLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "7Tdry6pBkKv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "7h4iibJskMZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_col=[col for col in df.columns if df[col].dtype=='O'] #-->Object-\"o\"\n",
        "cat_col"
      ],
      "metadata": {
        "id": "2qwhDeB7kOG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Gender\"].value_counts()"
      ],
      "metadata": {
        "id": "fg49lxTgkQNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.get_dummies(df[\"Gender\"],drop_first=True)"
      ],
      "metadata": {
        "id": "OTEjxOyvkR0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical = df[cat_col]\n",
        "categorical.head()\n"
      ],
      "metadata": {
        "id": "4YXhNQXAkTlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical = pd.get_dummies(categorical[\"Gender\"],drop_first=True)"
      ],
      "metadata": {
        "id": "grTV_YX7kVNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical"
      ],
      "metadata": {
        "id": "TOuyNz9rkWxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Num_col = [col for col in df.columns if df[col].dtype != \"O\"]\n",
        "Num_col"
      ],
      "metadata": {
        "id": "9OEqwgDVkYmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[Num_col].shape"
      ],
      "metadata": {
        "id": "StU5eFdKkaeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Numerical = df[Num_col]\n",
        "Numerical.head()"
      ],
      "metadata": {
        "id": "82cvJfqnkb8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Numerical.shape\n"
      ],
      "metadata": {
        "id": "lMhPExqWkfJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.concat([categorical,Numerical],axis=1)"
      ],
      "metadata": {
        "id": "TN--7fvfkg6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()\n"
      ],
      "metadata": {
        "id": "aXf4ltRfkjLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "# Ensure your dataframe is correctly named. If it's 'data', change '_df_4' to 'data'\n",
        "data.groupby('male').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "metadata": {
        "id": "qgScy4RKkptZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "id": "KyUiZFi3ks07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "# Convert boolean 'male' to int in the 'data' DataFrame\n",
        "data['male'] = data['male'].astype(int)\n",
        "\n",
        "# Define features (excluding target variable 'Calories')\n",
        "features = data.drop('Calories', axis=1) # Assuming 'Calories' is in 'data' DataFrame\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "standardized_data = scaler.fit_transform(features)\n",
        "\n",
        "# Apply PCA\n",
        "pca = PCA(n_components=2)  # Keep 2 principal components\n",
        "pca_result = pca.fit_transform(standardized_data)\n",
        "\n",
        "# Explained variance\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "print(\"Explained Variance by Principal Components:\", explained_variance)\n",
        "\n",
        "# Create a DataFrame with PCA results\n",
        "pca_df = pd.DataFrame(data=pca_result, columns=['PC1', 'PC2'])\n",
        "pca_df['Calories'] = data['Calories'].values  # Include target variable\n",
        "\n",
        "print(pca_df)"
      ],
      "metadata": {
        "id": "g9L53oHnkxpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into features (X) and target variable (y)\n",
        "X = df.drop('Calories', axis=1)  # Features\n",
        "y = df['Calories']  # Target\n",
        "\n",
        "# Split the dataset into training and testing sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Check the shapes of the resulting datasets\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n"
      ],
      "metadata": {
        "id": "VyO0hKlkkzYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: One-hot encoding categorical variables in the feature matrix\n",
        "X = pd.get_dummies(X, drop_first=True)  # Use drop_first=True to avoid the dummy variable trap\n"
      ],
      "metadata": {
        "id": "SY3nARK-M3WD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# One-hot encoding categorical features\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# List of models\n",
        "models = {\n",
        "    \"Linear Regression\": LinearRegression(),\n",
        "    \"Ridge Regression\": Ridge(),\n",
        "    \"Lasso Regression\": Lasso(),\n",
        "    \"Decision Tree\": DecisionTreeRegressor(),\n",
        "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingRegressor(),\n",
        "    \"AdaBoost\": AdaBoostRegressor(),\n",
        "    \"XGBoost\": XGBRegressor(),\n",
        "    \"SVR\": SVR(),\n",
        "    \"Extra Trees\": ExtraTreesRegressor(random_state=42)\n",
        "}\n",
        "\n",
        "# Dictionary to store metrics results for each model\n",
        "metrics_results = {}\n",
        "\n",
        "# Train each model and evaluate on the test set\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)  # Train the model\n",
        "    y_pred = model.predict(X_test)  # Make predictions on the test set\n",
        "\n",
        "    # Calculate regression metrics\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    # Store the results for each metric\n",
        "    metrics_results[name] = {\n",
        "        \"R-squared\": r2,\n",
        "        \"Mean Squared Error (MSE)\": mse,\n",
        "        \"Mean Absolute Error (MAE)\": mae,\n",
        "        \"Root Mean Squared Error (RMSE)\": rmse\n",
        "    }\n",
        "\n",
        "# Create a DataFrame to display all metrics for each model\n",
        "metrics_df = pd.DataFrame(metrics_results).T  # Transpose to show models as rows\n",
        "\n",
        "# Find the best model based on R-squared\n",
        "best_model_name = max(metrics_results, key=lambda x: metrics_results[x]['R-squared'])\n",
        "best_model_score = metrics_results[best_model_name]['R-squared']\n",
        "\n",
        "# Print the best model and its R-squared score\n",
        "print(f\"Best Model: {best_model_name}\")\n",
        "print(f\"R-squared Accuracy: {best_model_score:.4f}\")\n",
        "\n",
        "# Print all models' regression metrics\n",
        "print(\"\\nAll Models' Regression Metrics:\")\n",
        "print(metrics_df.round(4))  # Rounding for better readability\n"
      ],
      "metadata": {
        "id": "JSZSHDoZ1i3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy pandas matplotlib seaborn scikit-learn xgboost"
      ],
      "metadata": {
        "id": "7eJ9LGkvk4d4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set the style for the plots\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Define the metric to visualize (you can change this to 'Mean Absolute Error', 'Mean Squared Error', etc.)\n",
        "metric_to_visualize = 'R-squared'  # Change this to 'MAE', 'MSE', or 'RMSE' as needed\n",
        "\n",
        "# Create a bar plot for the chosen metric\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=metrics_df.index, y=metrics_df[metric_to_visualize], palette='viridis')\n",
        "\n",
        "# Add titles and labels\n",
        "plt.title(f'Comparison of Regression Models: {metric_to_visualize}', fontsize=16)\n",
        "plt.xlabel('Models', fontsize=14)\n",
        "plt.ylabel(metric_to_visualize, fontsize=14)\n",
        "plt.xticks(rotation=45)  # Rotate x labels for better readability\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7tI8H27FNp_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming you already have the metrics_df DataFrame from previous calculations\n",
        "# Here is a mock-up of how it would look. Please replace this with your actual metrics_df.\n",
        "metrics_results = {\n",
        "    \"Linear Regression\": {\"R-squared\": 0.85, \"Mean Squared Error (MSE)\": 1.2, \"Mean Absolute Error (MAE)\": 0.8, \"Root Mean Squared Error (RMSE)\": 1.1},\n",
        "    \"Ridge Regression\": {\"R-squared\": 0.84, \"Mean Squared Error (MSE)\": 1.3, \"Mean Absolute Error (MAE)\": 0.9, \"Root Mean Squared Error (RMSE)\": 1.14},\n",
        "    \"Lasso Regression\": {\"R-squared\": 0.83, \"Mean Squared Error (MSE)\": 1.4, \"Mean Absolute Error (MAE)\": 1.0, \"Root Mean Squared Error (RMSE)\": 1.18},\n",
        "    \"Decision Tree\": {\"R-squared\": 0.78, \"Mean Squared Error (MSE)\": 1.6, \"Mean Absolute Error (MAE)\": 1.2, \"Root Mean Squared Error (RMSE)\": 1.24},\n",
        "    \"Random Forest\": {\"R-squared\": 0.90, \"Mean Squared Error (MSE)\": 0.9, \"Mean Absolute Error (MAE)\": 0.7, \"Root Mean Squared Error (RMSE)\": 0.95},\n",
        "    \"Gradient Boosting\": {\"R-squared\": 0.88, \"Mean Squared Error (MSE)\": 1.1, \"Mean Absolute Error (MAE)\": 0.75, \"Root Mean Squared Error (RMSE)\": 1.05},\n",
        "    \"AdaBoost\": {\"R-squared\": 0.82, \"Mean Squared Error (MSE)\": 1.5, \"Mean Absolute Error (MAE)\": 1.1, \"Root Mean Squared Error (RMSE)\": 1.22},\n",
        "    \"XGBoost\": {\"R-squared\": 0.91, \"Mean Squared Error (MSE)\": 0.85, \"Mean Absolute Error (MAE)\": 0.65, \"Root Mean Squared Error (RMSE)\": 0.92},\n",
        "    \"SVR\": {\"R-squared\": 0.80, \"Mean Squared Error (MSE)\": 1.4, \"Mean Absolute Error (MAE)\": 0.85, \"Root Mean Squared Error (RMSE)\": 1.18},\n",
        "    \"Extra Trees\": {\"R-squared\": 0.89, \"Mean Squared Error (MSE)\": 0.95, \"Mean Absolute Error (MAE)\": 0.72, \"Root Mean Squared Error (RMSE)\": 0.97},\n",
        "}\n",
        "\n",
        "# Create a DataFrame from the metrics results\n",
        "metrics_df = pd.DataFrame(metrics_results).T  # Transpose to show models as rows\n",
        "\n",
        "# Set the style for the plots\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Metrics to visualize\n",
        "metrics_to_visualize = ['R-squared', 'Mean Absolute Error (MAE)', 'Mean Squared Error (MSE)', 'Root Mean Squared Error (RMSE)']\n",
        "\n",
        "# Create subplots\n",
        "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\n",
        "\n",
        "# Flatten the axes array for easier iteration\n",
        "axes = axes.flatten()\n",
        "\n",
        "for ax, metric in zip(axes, metrics_to_visualize):\n",
        "    sns.barplot(x=metrics_df.index, y=metrics_df[metric], palette='viridis', ax=ax)\n",
        "    ax.set_title(f'Comparison of Regression Models: {metric}', fontsize=14)\n",
        "    ax.set_xlabel('Models', fontsize=12)\n",
        "    ax.set_ylabel(metric, fontsize=12)\n",
        "    ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8hMVxDAkOPic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import xgboost as xgb\n",
        "\n",
        "# Sample DataFrame creation (replace this with your actual DataFrame)\n",
        "data = {\n",
        "    'male': [True, False, True, False, False],\n",
        "    'Age': [68, 20, 69, 34, 27],\n",
        "    'Height': [190.0, 166.0, 179.0, 179.0, 154.0],\n",
        "    'Weight': [94.0, 60.0, 79.0, 71.0, 58.0],\n",
        "    'Duration': [29.0, 14.0, 5.0, 13.0, 10.0],\n",
        "    'Heart_Rate': [105.0, 94.0, 88.0, 100.0, 81.0],\n",
        "    'Body_Temp': [40.8, 40.3, 38.7, 40.5, 39.8],\n",
        "    'Calories': [231.0, 66.0, 26.0, 71.0, 35.0]\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Convert 'male' column to numeric (1 for True, 0 for False)\n",
        "df['male'] = df['male'].astype(int)\n",
        "\n",
        "# Split the data into features and target variable\n",
        "X = df.drop(columns=['Calories'])  # Features\n",
        "y = df['Calories']  # Target variable\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the XGBoost model\n",
        "model_xgb = xgb.XGBRegressor(objective='reg:squarederror')  # Define model with parameters\n",
        "model_xgb.fit(X_train, y_train)  # Fit the model\n",
        "\n",
        "# Make predictions from the XGBoost model\n",
        "y_pred = model_xgb.predict(X_test)\n",
        "\n",
        "# Calculate R-squared and RMSE\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "# Print R-squared and RMSE\n",
        "print(f\"R-squared: {r2:.4f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
        "\n",
        "# Calculate residuals\n",
        "residuals = y_test - y_pred\n",
        "\n",
        "# Plot residuals\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Residuals Histogram\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.histplot(residuals, bins=30, kde=True, color='blue')\n",
        "plt.title('Residuals Histogram')\n",
        "plt.xlabel('Residuals')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# Residuals vs Fitted values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(y_pred, residuals, alpha=0.5, color='orange')\n",
        "plt.axhline(0, color='red', linestyle='--')\n",
        "plt.title('Residuals vs Fitted Values')\n",
        "plt.xlabel('Fitted Values')\n",
        "plt.ylabel('Residuals')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Feature Importance\n",
        "importances = model_xgb.feature_importances_  # Get feature importances\n",
        "feature_names = X_train.columns  # Get feature names\n",
        "\n",
        "# Create a DataFrame for visualization\n",
        "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
        "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Plot feature importance\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Importance', y='Feature', data=importance_df.head(10), palette='viridis')\n",
        "plt.title('Top 10 Feature Importances')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BNdiiJ-DoNRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Sample data\n",
        "data = {\n",
        "    'male': [True, False, True, False, False],\n",
        "    'Age': [68, 20, 69, 34, 27],\n",
        "    'Height': [190.0, 166.0, 179.0, 179.0, 154.0],\n",
        "    'Weight': [94.0, 60.0, 79.0, 71.0, 58.0],\n",
        "    'Duration': [29.0, 14.0, 5.0, 13.0, 10.0],\n",
        "    'Heart_Rate': [105.0, 94.0, 88.0, 100.0, 81.0],\n",
        "    'Body_Temp': [40.8, 40.3, 38.7, 40.5, 39.8],\n",
        "    'Calories': [231.0, 66.0, 26.0, 71.0, 35.0]\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Encode 'male' as 1 or 0\n",
        "df['male'] = df['male'].astype(int)\n",
        "\n",
        "# Split data into features and target\n",
        "X = df.drop('Calories', axis=1)\n",
        "y = df['Calories']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the XGBoost model\n",
        "model_xgb = xgb.XGBRegressor(objective='reg:squarederror')  # Specify objective\n",
        "model_xgb.fit(X_train, y_train)\n",
        "\n",
        "# Function to take user input and predict calories\n",
        "def predict_calories(model):\n",
        "    # Create a dictionary to hold user inputs\n",
        "    user_input = {}\n",
        "\n",
        "    # Collect user input for each feature with proper prompts\n",
        "    user_input['Age'] = float(input(\"Enter Age: \"))\n",
        "    user_input['Height'] = float(input(\"Enter Height (in cm): \"))\n",
        "    user_input['Weight'] = float(input(\"Enter Weight (in kg): \"))\n",
        "    user_input['Duration'] = float(input(\"Enter Duration (in minutes): \"))\n",
        "    user_input['Heart_Rate'] = float(input(\"Enter Heart Rate: \"))\n",
        "    user_input['Body_Temp'] = float(input(\"Enter Body Temperature (in Â°C): \"))\n",
        "\n",
        "    # Collect input for male and validate\n",
        "    while True:\n",
        "        male_input = input(\"Are you male? (1 for Yes, 0 for No): \").strip()\n",
        "        if male_input in ['1', '0']:\n",
        "            user_input['male'] = int(male_input)  # Convert input to int\n",
        "            break\n",
        "        else:\n",
        "            print(\"Invalid input. Please enter '1' for Yes or '0' for No.\")\n",
        "\n",
        "    # Convert user input to DataFrame\n",
        "    input_df = pd.DataFrame([user_input])\n",
        "\n",
        "    # Reorder the columns to match the training data\n",
        "    input_df = input_df[X.columns]  # Ensure the order matches the training set\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(input_df)\n",
        "\n",
        "    # Print the prediction\n",
        "    print(f\"Predicted Calories burned: {prediction[0]:.2f}\")\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    predict_calories(model_xgb)\n"
      ],
      "metadata": {
        "id": "4cr6hm8NoREr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SzOH7IKfDauA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}